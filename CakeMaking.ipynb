{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056de820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tcga_astro_filtered', 'tcga_gbm_filtered', 'tcga_olio_filtered']\n",
      "uint8\n",
      "İşlenen Dosya: dataset/tcga_astro_filtered/TCGA-P5-A737_30.npy, shape: (63810, 240, 240)\n",
      "500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m npy_files:\n\u001b[1;32m     54\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, file)\n\u001b[0;32m---> 55\u001b[0m         loadNp(file_path\u001b[38;5;241m=\u001b[39mfile_path,label\u001b[38;5;241m=\u001b[39mlabel)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Listeyi numpy array'e çevir\u001b[39;00m\n\u001b[1;32m     58\u001b[0m selected_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(selected_images)\n",
      "Cell \u001b[0;32mIn[1], line 27\u001b[0m, in \u001b[0;36mloadNp\u001b[0;34m(file_path, label)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mloadNp\u001b[39m(file_path , label):\n\u001b[0;32m---> 27\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(file_path)  \u001b[38;5;66;03m# shape: [slice, H, W]\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mİşlenen Dosya: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/numpy/lib/npyio.py:456\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    454\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mread_array(fid, allow_pickle\u001b[38;5;241m=\u001b[39mallow_pickle,\n\u001b[1;32m    457\u001b[0m                                  pickle_kwargs\u001b[38;5;241m=\u001b[39mpickle_kwargs,\n\u001b[1;32m    458\u001b[0m                                  max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.12/site-packages/numpy/lib/format.py:809\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    808\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfromfile(fp, dtype\u001b[38;5;241m=\u001b[39mdtype, count\u001b[38;5;241m=\u001b[39mcount)\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    822\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "# Ana dizin\n",
    "root_dir = 'dataset'\n",
    "\n",
    "# Çıktı dosyaları\n",
    "output_images_file = 'selected_images.npy'\n",
    "output_labels_file = 'selected_labels.npy'\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Klasörleri al\n",
    "class_folders = [f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))]\n",
    "if '__pycache__' in class_folders:\n",
    "    class_folders.remove('__pycache__')\n",
    "class_folders.sort()\n",
    "print(class_folders)\n",
    "selected_images = []\n",
    "selected_labels = []\n",
    "\n",
    "\n",
    "def loadNp(file_path , label):\n",
    "    data = np.load(file_path)  # shape: [slice, H, W]\n",
    "    print(data.dtype)\n",
    "    print(f\"İşlenen Dosya: {file_path}, shape: {data.shape}\")\n",
    "    \n",
    "\n",
    "    ver_cent = data.shape[1]//2\n",
    "    hor_cent = data.shape[2]//2\n",
    "\n",
    "    size = 240//2\n",
    "    \n",
    "    data = data[:,ver_cent-size:ver_cent+size,hor_cent-size:hor_cent+size]\n",
    "\n",
    "\n",
    "    slice_count = data.shape[0]\n",
    "    slice_indices = random.sample(range(slice_count), min(500, slice_count))\n",
    "    print(len(slice_indices))\n",
    "    selected_images.extend(data[slice_indices])\n",
    "    for i in range(500):\n",
    "        selected_labels.append(label)\n",
    "    gc.collect()\n",
    "    del data\n",
    "\n",
    "for label, folder in enumerate(class_folders):\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "    npy_files = [f for f in os.listdir(folder_path) if f.endswith('.npy')]\n",
    "\n",
    "    for file in npy_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        loadNp(file_path=file_path,label=label)\n",
    "        \n",
    "# Listeyi numpy array'e çevir\n",
    "selected_images = np.array(selected_images)\n",
    "selected_labels = np.array(selected_labels)\n",
    "\n",
    "# Kaydet\n",
    "np.save(output_images_file, selected_images)\n",
    "np.save(output_labels_file, selected_labels)\n",
    "\n",
    "print(f\"Toplam {len(selected_images)} slice ve {len(selected_labels)} etiket kaydedildi.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e90498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dcm_file(dcm_path, save_dir):\n",
    "    try:\n",
    "        # Read using force to speed up + stop after pixel data\n",
    "        ds = pd.dcmread(dcm_path, force=True, stop_before_pixels=False)\n",
    "\n",
    "        # Decode JPEG2000 more efficiently (if applicable)\n",
    "        arr = ds.pixel_array  # Pydicom will use pylibjpeg/gdcm if installed\n",
    "\n",
    "        # Optional: apply VOI LUT if necessary\n",
    "        # arr = apply_voi_lut(arr, ds)\n",
    "\n",
    "        # Build output path\n",
    "        pid = os.path.basename(dcm_path)[:17]\n",
    "        \n",
    "        h = ds.TotalPixelMatrixColumns\n",
    "        w = ds.TotalPixelMatrixRows\n",
    "        \n",
    "        output_path = os.path.join(save_dir, pid +\"(\" + str(w)+\"x\" + str(h) + \")\" + \".npy\")\n",
    "\n",
    "        # Save as NumPy file\n",
    "        np.save(output_path, arr)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {dcm_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a9153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: tcga_olio_filtered\n",
      "Processing folder: tcga_astro_filtered\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    print(f\"Processing folder: {folder}\")  \n",
    "    \n",
    "    if folder == \"tcga_olio_filtered\":\n",
    "        label = 0\n",
    "    elif folder == \"tcga_astro_filtered\":\n",
    "        label = 1\n",
    "    elif folder == \"tcga_gbm_filtered\":\n",
    "        label = 2\n",
    "    \n",
    "    path = os.path.join(\"./dataset2\", folder)\n",
    "    del_and_crt_dir(path)\n",
    "\n",
    "    # Use ThreadPoolExecutor to process files in parallel\n",
    "    dcm_files = glob.glob(os.path.join(folder, \"*.dcm\"))\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        executor.map(lambda file: process_dcm_file(file, path), dcm_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d8f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_shape = (240, 240)  # Veya gri ise (240, 240)\n",
    "\n",
    "for i, img in enumerate(selected_images):\n",
    "    if img.shape != expected_shape:\n",
    "        print(f\"Image {i} has shape: {img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e18753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resized_images = [cv2.resize(img, (240, 240)) for img in selected_images]\n",
    "np_images = np.array(resized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9bd8e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np_labels = np.array(labels)\n",
    "\n",
    "np.save('images.npy', np_images)  \n",
    "np.save('labels.npy', np_labels)              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5407b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# path = \"TCGA-R8-A6MK_93789065-5d39-4725-af39-41e3c23a2289.dcm\"\n",
    "# process_dcm_file(path, \"./\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
