{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tcga_lgg_astro_filtered/TCGA-TM-A7CF_1fe1a0ed-c832-4096-a7cc-72b61d4fb592.dcm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from pydicom.pixels import iter_pixels\n",
    "\n",
    "class DICOMClassificationModel:\n",
    "    def __init__(self, img_height=224, img_width=224):\n",
    "        \"\"\"\n",
    "        DICOM görüntüleri için VGG16 sınıflandırma modeli\n",
    "        \n",
    "        Args:\n",
    "            img_height (int): Görüntü yüksekliği\n",
    "            img_width (int): Görüntü genişliği\n",
    "        \"\"\"\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.classes = ['Tcga_lgg_astro_filtered', 'Tcga_gbm_filtered', 'Tcga_lgg_olio_filtered']\n",
    "        self.model = self.build_model()\n",
    "    \n",
    "    def load_dicom_images(self, base_dir):\n",
    "        \"\"\"\n",
    "        DICOM dosyalarını yükleme ve sınıflandırma\n",
    "        \n",
    "        Args:\n",
    "            base_dir (str): DICOM dosyaları içeren dizin\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Görüntüler ve etiketler\n",
    "        \"\"\"\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(base_dir, class_name)\n",
    "            image_batch = []\n",
    "            label_batch = []\n",
    "            \n",
    "            # Her bir DICOM dosyası için\n",
    "            for dcm_file in os.listdir(class_dir):\n",
    "                if dcm_file.endswith('.dcm'):\n",
    "                    dcm_path = os.path.join(class_dir, dcm_file)\n",
    "                    print(dcm_path)\n",
    "\n",
    "                    try:\n",
    "                        ds_file = pydicom.dcmread(dcm_path)\n",
    "                        # DICOM dosyasındaki her bir pikseli iterate etme\n",
    "                        for arr in iter_pixels(ds_file):\n",
    "                            # Görüntüyü yeniden boyutlandırma\n",
    "                            resized_image = resize(\n",
    "                                arr, \n",
    "                                (self.img_height, self.img_width), \n",
    "                                anti_aliasing=True\n",
    "                            )\n",
    "                            \n",
    "                            # Tek kanallı görüntüyü 3 kanallı hale getirme\n",
    "                            if len(resized_image.shape) == 2:\n",
    "                                resized_image_3channel = np.stack((resized_image,)*3, axis=-1)\n",
    "                            elif resized_image.shape[2] == 1:\n",
    "                                resized_image_3channel = np.repeat(resized_image, 3, axis=2)\n",
    "                            else:\n",
    "                                resized_image_3channel = resized_image\n",
    "                            \n",
    "                            # Görüntüyü ekle\n",
    "                            image_batch.append(resized_image_3channel)\n",
    "                            \n",
    "                            # Etiketi ekle\n",
    "                            label = self.classes.index(class_name)\n",
    "                            label_batch.append(label)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Hata oluştu {dcm_path}: {e}\")\n",
    "            \n",
    "            images.append(image_batch)\n",
    "            labels.append(label_batch)\n",
    "                \n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        VGG16 modelini fine-tune için hazırlama\n",
    "        \n",
    "        Returns:\n",
    "            tensorflow.keras.Model: Hazırlanmış model\n",
    "        \"\"\"\n",
    "        # Temel VGG16 modelini önceden eğitilmiş ağırlıklarla yükleme\n",
    "        base_model = VGG16(\n",
    "            weights='imagenet', \n",
    "            include_top=False, \n",
    "            input_shape=(self.img_height, self.img_width, 3)\n",
    "        )\n",
    "        \n",
    "        # Temel modelin katmanlarını dondurma\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        # Yeni sınıflandırıcı katmanları ekleme\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        output = Dense(len(self.classes), activation='softmax')(x)\n",
    "        \n",
    "        model = Model(inputs=base_model.input, outputs=output)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def compile_model(self, learning_rate=0.0001):\n",
    "        \"\"\"\n",
    "        Modeli derlemek için metod\n",
    "        \n",
    "        Args:\n",
    "            learning_rate (float): Öğrenme oranı\n",
    "        \"\"\"\n",
    "        self.model.compile(\n",
    "            optimizer=Adam(learning_rate=learning_rate),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    def train(self, base_dir, test_size=0.2, epochs=20, batch_size=32):\n",
    "        \"\"\"\n",
    "        Modeli eğitme metodu\n",
    "        \n",
    "        Args:\n",
    "            base_dir (str): DICOM dosyaları içeren dizin\n",
    "            test_size (float): Test verisi oranı\n",
    "            epochs (int): Eğitim epoch sayısı\n",
    "            batch_size (int): Mini toplu işlem boyutu\n",
    "        \"\"\"\n",
    "        # Görüntüleri ve etiketleri yükleme\n",
    "        X, y = self.load_dicom_images(base_dir)\n",
    "        \n",
    "        # Veriyi eğitim ve test olarak ayırma\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Veriyi ön işleme\n",
    "        X_train = preprocess_input(X_train)\n",
    "        X_test = preprocess_input(X_test)\n",
    "        \n",
    "        # Fine-tuning için modelin son katmanlarını açma\n",
    "        for layer in self.model.layers[:15]:\n",
    "            layer.trainable = False\n",
    "        for layer in self.model.layers[15:]:\n",
    "            layer.trainable = True\n",
    "        \n",
    "        # Modeli derleme\n",
    "        self.compile_model()\n",
    "        \n",
    "        # Modeli eğitme\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def save_model(self, save_path):\n",
    "        \"\"\"\n",
    "        Modeli kaydetme metodu\n",
    "        \n",
    "        Args:\n",
    "            save_path (str): Model kayıt yolu\n",
    "        \"\"\"\n",
    "        self.model.save(save_path)\n",
    "    \n",
    "    def plot_training_history(self, history):\n",
    "        \"\"\"\n",
    "        Eğitim geçmişini görselleştirme\n",
    "        \n",
    "        Args:\n",
    "            history: Keras eğitim geçmişi\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Doğruluk grafiği\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')\n",
    "        plt.plot(history.history['val_accuracy'], label='Test Doğruluğu')\n",
    "        plt.title('Model Doğruluğu')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Doğruluk')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Kayıp grafiği\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['loss'], label='Eğitim Kaybı')\n",
    "        plt.plot(history.history['val_loss'], label='Test Kaybı')\n",
    "        plt.title('Model Kaybı')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Kayıp')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Örnek kullanım\n",
    "if __name__ == \"__main__\":\n",
    "    # DICOM veri dizini\n",
    "    base_dir = ''\n",
    "    \n",
    "    # Modeli oluşturma\n",
    "    dicom_model = DICOMClassificationModel()\n",
    "    \n",
    "    # Modeli eğitme\n",
    "    history = dicom_model.train(base_dir)\n",
    "    \n",
    "    # Eğitim geçmişini görselleştirme\n",
    "    dicom_model.plot_training_history(history)\n",
    "    \n",
    "    # Modeli kaydetme\n",
    "    dicom_model.save_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<string>, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<string>:43\u001b[0;36m\u001b[0m\n\u001b[0;31m    image_batch = []\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
